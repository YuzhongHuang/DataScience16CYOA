{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>\n",
    "    Naive Bayesian By Hand\n",
    "</h1>\n",
    "<p> \n",
    "    Now we will try to implement our naive bayesian then compare it to scikit learns algorithm.\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "    We have 5 different potential reviews: 0,1,2,3,4 and will need 5 class probabilities to represent each potential outcome. We will get the frequency per word and then calculate the probability for each of the class probabilites by dividing the frequency of word with the total number of occurences that word occurs in that review. To get the probability of a phrase or sentence we multiply the probability for each word in that phrase against he probability of any document that expresses that sentiment.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "     We will start out by pre-processing our data: removing punctuation and stopwords\n",
    "</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = add_processed_review(train)\n",
    "test = add_processed_review(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    Now the goal is to create the functions and data sets we will be using to calculate a sentiment for any given sentence or phrase\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we will start by creating 5 probabilities for any given document that expresses that sentiment\n",
    "doc_prob_0 = float(len(train[train.Sentiment == 0]))/len(train)\n",
    "doc_prob_1 = float(len(train[train.Sentiment == 1]))/len(train)\n",
    "doc_prob_2 = float(len(train[train.Sentiment == 2]))/len(train)\n",
    "doc_prob_3 = float(len(train[train.Sentiment == 3]))/len(train)\n",
    "doc_prob_4 = float(len(train[train.Sentiment == 4]))/len(train)\n",
    "\n",
    "# we create 5 separate histograms for each case w/ frequency\n",
    "dict0 = calc_sentiment_probabilities(0)\n",
    "dict1 = calc_sentiment_probabilities(1)\n",
    "dict2 = calc_sentiment_probabilities(2)\n",
    "dict3 = calc_sentiment_probabilities(3)\n",
    "dict4 = calc_sentiment_probabilities(4)\n",
    "dictionary_reference = [dict0,dict1,dict2,dict3,dict4]\n",
    "\n",
    "def create_reference_histogram(data):\n",
    "    \"\"\"Takes: A dataset of strings\n",
    "       Returns: Dictionary w/ keys-words, value- list of values[sent=0,sent=1,sent=2,sent=3,sent=4,total] \n",
    "    \"\"\"\n",
    "    histogram = {}\n",
    "    #we will iterate through each sentence and word and increment the index of the list of values\n",
    "    for index, sentence in df.iterrows():\n",
    "        sentiment_value = df.Sentiment[index]\n",
    "        words = sentence.split()\n",
    "        for word in words:\n",
    "            if word in histogram:\n",
    "                histogram[word][5] +=1\n",
    "                histogram[word][sentiment_value] += 1\n",
    "            else:\n",
    "                histogram[word]= np.array([0,0,0,0,0,1])\n",
    "                histogram[word][sentiment_value] += 1\n",
    "    return histogram \n",
    "\n",
    "def calc_sentiment_probabilities(ref_dict):\n",
    "    \"\"\" Takes: A sentiment value you are trying to test for\n",
    "        Returns: Dictionary w/ keys-word value-probability of that word matching the value\n",
    "        frequency = matching_value_freq/total_freq\n",
    "    \"\"\"   \n",
    "    # make a copy of ref_dict\n",
    "    final_dict = ref_dict\n",
    "    # we will iterate through every word in the dictionary and change the values from a list to the probability we want \n",
    "    # if the value is 0 we will make probability 1 as part of smooth\n",
    "    for word in ref_dict:\n",
    "        final_dict[word] = float(final_dict[word][0:4])/final_dict[word][5]\n",
    "    return final_dict\n",
    "\n",
    "def make_predictions(data):\n",
    "    \"\"\" Takes: Test data\n",
    "        Returns: Submission File w. Sentiment value calculated\n",
    "    \"\"\"\n",
    "    submission = data\n",
    "    for sentence in submission:\n",
    "        prob_list = []\n",
    "        for word in sentence:\n",
    "            \n",
    "    return submission \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
